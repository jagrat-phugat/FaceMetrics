{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6247a6d4",
   "metadata": {},
   "source": [
    "# Age and Gender Recognition\n",
    "This Jupyter Notebook implements a machine learning model for age and gender recognition.\n",
    "\n",
    "## Overview\n",
    "The notebook includes the following steps:\n",
    "- Data Preprocessing\n",
    "- Model Training\n",
    "- Evaluation and Results\n",
    "\n",
    "## Dataset\n",
    "Describe the dataset used (source, number of images, labels, etc.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af8fac8",
   "metadata": {},
   "source": [
    "## Importing Required Libraries\n",
    "We start by importing necessary libraries such as TensorFlow, OpenCV, and NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe795aca",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Here, we load and preprocess the dataset for training. This includes resizing images, normalizing pixel values, and splitting the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faceBox(faceNet, frame):\n",
    "    frameHeight = frame.shape[0]\n",
    "    frameWidth = frame.shape[1]\n",
    "    blob = cv.dnn.blobFromImage(frame, 1.0, (227, 227), [104, 117, 123], swapRB = False)\n",
    "    faceNet.setInput(blob)\n",
    "    detection = faceNet.forward()\n",
    "    bbox = []\n",
    "    for i in range(detection.shape[2]):\n",
    "        confidence = detection[0,0,i,2]\n",
    "        if confidence > 0.7:\n",
    "            x1 = int(detection[0,0,i,3]*frameWidth)\n",
    "            y1 = int(detection[0, 0, i, 4]*frameHeight)\n",
    "            x2 = int(detection[0,0,i,5]*frameWidth)\n",
    "            y2 = int(detection[0, 0, i, 6]*frameHeight)\n",
    "            bbox.append([x1, y1, x2, y2])\n",
    "            cv.rectangle(frame, (x1, y1), (x2,y2), (90,255,0), 1)\n",
    "    return frame, bbox\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4de1ce9",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "The model architecture is defined using a deep learning framework such as TensorFlow/Keras. We use convolutional layers to extract features from images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cccea6",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "We compile and train the model using an appropriate loss function and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "faceProto = \"opencv_face_detector.pbtxt\"\n",
    "faceModel = \"opencv_face_detector_uint8.pb\"\n",
    "\n",
    "ageProto = \"age_deploy.prototxt\"\n",
    "ageModel = \"age_net.caffemodel\"\n",
    "\n",
    "genderProto = \"gender_deploy.prototxt\"\n",
    "genderModel = \"gender_net.caffemodel\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d7b8e7",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "We evaluate the model's performance on the test dataset using accuracy, precision, recall, and other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceNet = cv.dnn.readNet(faceModel, faceProto)\n",
    "ageNet = cv.dnn.readNet(ageModel, ageProto)\n",
    "genderNet = cv.dnn.readNet(genderModel, genderProto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_MEAN_VALUES = (78.42634, 87.7689, 114.89585)\n",
    "ageList = ['(0-2)', '(2-4)', '(4-6)', '(6-10)', '(10-15)', '(15-18)', '(18-23)', '(23-26)', '(26-32)', '(32-37)', '(37-43)', '(43-50)', '(50-55)', '(55-60)', '(60+)']\n",
    "genderList = ['Male', 'Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding = 20\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    frame, bbox = faceBox(faceNet, frame)\n",
    "    for box in bbox:\n",
    "        face = frame[max(0, box[1]-padding):min(box[3]+padding, frame.shape[0]-1), max(0, box[0]-padding):min(box[2]+padding, frame.shape[1]-1)]\n",
    "        blob = cv.dnn.blobFromImage(face, 1.0, (227,227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "        \n",
    "        genderNet.setInput(blob)\n",
    "        gender_pred = genderNet.forward()\n",
    "        gender = genderList[gender_pred[0].argmax()]\n",
    "\n",
    "        ageNet.setInput(blob)\n",
    "        age_pred = ageNet.forward()\n",
    "        age = ageList[age_pred[0].argmax()]\n",
    "\n",
    "        label = \"{},{}\".format(gender, age)\n",
    "        cv.putText(frame, label, (box[0], box[1]-10), cv.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "\n",
    "    cv.imshow(\"Age-Gender\", frame)\n",
    "    k = cv.waitKey(1)\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "video.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c0ed5a4",
   "metadata": {},
   "source": [
    "## Results and Conclusion\n",
    "We analyze the model's predictions and saw that the model was performing pretty good on gender classification. However, the model was giving correct age bracket of the individual, but in absence of adequate lightning, the age recognition was not working properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
